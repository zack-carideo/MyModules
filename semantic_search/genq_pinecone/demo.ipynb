{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zjc10\\Desktop\\Projects\\envs\\embed_db\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO:faiss.loader:Loading faiss with AVX2 support.\n",
      "INFO:faiss.loader:Could not load library with AVX2 support due to:\n",
      "ModuleNotFoundError(\"No module named 'faiss.swigfaiss_avx2'\")\n",
      "INFO:faiss.loader:Loading faiss.\n",
      "INFO:faiss.loader:Successfully loaded faiss.\n",
      "INFO:__main__:|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File DOES exist:\n",
      "\t c:\\Users\\zjc10\\Desktop\\Projects\\code\\MyModules\\semantic_search\\genq_pinecone\\config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sys,os,logging, gc\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer, T5Tokenizer,T5TokenizerFast, T5ForConditionalGeneration\n",
    "import torch \n",
    "#set up basic logging\n",
    "logging.basicConfig()\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "logger =  logging.getLogger(__name__)\n",
    "\n",
    "#config path \n",
    "root_ = os.path.abspath(\"\")\n",
    "cfg_path = Path(root_) / \"config.yaml\"\n",
    "\n",
    "#custom imports\n",
    "sys.path.append(root_)\n",
    "from util.misc import LoadCFG, seed_all\n",
    "from util.data import load_data\n",
    "from util.embedding_ops import query_ops\n",
    "from util.model_ops import build_model \n",
    "from util.index_ops import ScalableSemanticSearch\n",
    "\n",
    "#set seed \n",
    "SEED = 42\n",
    "seed_all(SEED)\n",
    "\n",
    "#load cfg params\n",
    "cfg = LoadCFG(cfg_path, base_dir = root_).load()\n",
    "DATA_PATH = cfg.data.input.data_path\n",
    "SAVE_DIR = Path(cfg.data.output.data_save_dir)\n",
    "MODEL_SAVE_DIR = Path(cfg.model.model_save_dir)\n",
    "\n",
    "NSAMPS = cfg.model.n_samps\n",
    "TOK_BATCH_SIZE = cfg.model.tokenizer.batch_size\n",
    "BI_ENCODER_MODEL_NAME = cfg.model.bi_encoder.model_name\n",
    "EPOCHS = cfg.model.n_epochs\n",
    "BI_ENCODER_BATCH_SIZE =  cfg.model.bi_encoder.batch_size\n",
    "\n",
    "\n",
    "#device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#tokenizer setup\n",
    "return_tensors = cfg.model.tokenizer.return_tensors\n",
    "padding =  cfg.model.tokenizer.padding\n",
    "return_overflow_tokens= cfg.model.tokenizer.return_overflow_tokens\n",
    "max_seq_len = cfg.model.tokenizer.max_seq_len\n",
    "truncation = cfg.model.tokenizer.truncation \n",
    "stride = cfg.model.tokenizer.stride \n",
    "\n",
    "#query generator setup\n",
    "GENQ_MODEL_NAME = cfg.model.query_gen.model_name \n",
    "N_QUERIES_PER_PASSAGE =  cfg.model.query_gen.n_queries_per_passage \n",
    "\n",
    "#clean up gpu \n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "logger.info(torch.cuda.memory_summary(device='cuda', abbreviated=True))\n",
    "\n",
    "#create output folder if it doesnt exist\n",
    "if not SAVE_DIR.is_dir():\n",
    "    assert (not SAVE_DIR.is_file()), f'a directory to save outputs must be passed, you passed a full file path: {save_dir}'\n",
    "    if not SAVE_DIR.parent.is_dir(): \n",
    "        os.mkdir(str(SAVE_DIR.parent))\n",
    "        os.mkdir(str(SAVE_DIR))\n",
    "    else:\n",
    "        os.mkdir(str(SAVE_DIR))\n",
    "    logger.info(f\"new output directory created:{SAVE_DIR}\")\n",
    "\n",
    "if not MODEL_SAVE_DIR.is_dir():\n",
    "    assert SAVE_DIR.parent.is_dir(), f'parent directory: {SAVE_DIR} does not exist'\n",
    "    os.mkdir(str(MODEL_SAVE_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:loading data from huggyface\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': ['5733be284776f41900661182'],\n",
       " 'title': ['University_of_Notre_Dame'],\n",
       " 'context': ['Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.'],\n",
       " 'question': ['To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?'],\n",
       " 'answers': [{'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logging.info('loading data from huggyface')\n",
    "df = load_data( load_from_directory=False \n",
    "               , hf_dataset_name = 'squad' \n",
    "               , split ='train') \n",
    "\n",
    "df[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:extracting text passages to generate queries for\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "The beginning of the Neolithic culture is considered to be in the Levant (Jericho, modern-day West Bank) about 10,200 â€“ 8,800 BC. It developed directly from the Epipaleolithic Natufian culture in the region, whose people pioneered the use of wild cereals, which then evolved into true farming. The Natufian period was between 12,000 and 10,200 BC, and the so-called \"proto-Neolithic\" is now included in the Pre-Pottery Neolithic (PPNA) between 10,200 and 8,800 BC. As the Natufians had become dependent on wild cereals in their diet, and a sedentary way of life had begun among them, the climatic changes associated with the Younger Dryas are thought to have forced people to develop farming.\n"
     ]
    }
   ],
   "source": [
    "logging.info('extracting text passages to generate queries for')\n",
    "passages = list(set(df['context']))[:NSAMPS]\n",
    "print(len(passages))\n",
    "print(passages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:creating tokenizer and model to use in bi-encoder\n",
      "INFO:__main__:creating model to use in bi-encoder\n",
      "You are using the legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "logger.info('creating tokenizer and model to use in bi-encoder')\n",
    "logger.info('creating model to use in bi-encoder')\n",
    "#tokenizer  = T5Tokenizer.from_pretrained(GENQ_MODEL_NAME, legacy=False) \n",
    "qgen_model = T5ForConditionalGeneration.from_pretrained(GENQ_MODEL_NAME)\n",
    "tokenizer = T5TokenizerFast.from_pretrained(GENQ_MODEL_NAME, do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:forcing model into eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#call eval() to force / ensure model is running in 'INFERENCE MODE' and not 'TRAINING' mode\n",
    "logger.info('forcing model into eval mode')\n",
    "qgen_model.eval()\n",
    "model = qgen_model.to(device)\n",
    "#tokenizer = tokenizer\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:initalize embedding querier\n"
     ]
    }
   ],
   "source": [
    "#initalize class to generate queries from passages\n",
    "logger.info('initalize embedding querier')\n",
    "queryer = query_ops(\n",
    "     tokenizer\n",
    "    , qgen_model \n",
    "    , SAVE_DIR\n",
    "    , n_queries_per_passage = N_QUERIES_PER_PASSAGE\n",
    "    , save_batch_size = 1000\n",
    "    , train_batch_size = TOK_BATCH_SIZE    \n",
    "    , return_tensors = return_tensors\n",
    "    , padding =  padding\n",
    "    , return_overflowing_tokens= return_overflow_tokens\n",
    "    , max_seq_len = max_seq_len\n",
    "    , truncation = truncation \n",
    "    , stride = stride \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:generating query, passage key value pairs\n",
      "2it [00:18,  9.40s/it]\n"
     ]
    }
   ],
   "source": [
    "#generate query,passage key value pairs , save to disk , return paths \n",
    "logger.info('generating query, passage key value pairs')\n",
    "query_passage_outpaths = queryer.gen_queries_from_passages(passages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'In 2012, resident foreigners made up 23.3% of the population. Most of these (64%) were from European Union or EFTA countries. Italians were the largest single group of foreigners with 15.6% of total foreign population. They were closely followed by Germans (15.2%), immigrants from Portugal (12.7%), France (5.6%), Serbia (5.3%), Turkey (3.8%), Spain (3.7%), and Austria (2%). Immigrants from Sri Lanka, most of them former Tamil refugees, were the largest group among people of Asian origin (6.3%). Additionally, the figures from 2012 show that 34.7% of the permanent resident population aged 15 or over in Switzerland, i.e. 2,335,000 persons, had an immigrant background. A third of this population (853,000) held Swiss citizenship. Four fifths of persons with an immigration background were themselves immigrants (first generation foreigners and native-born and naturalised Swiss citizens), whereas one fifth were born in Switzerland (second generation foreigners and native-born and naturalised Swiss citizens). In the 2000s, domestic and international institutions expressed concern about what they perceived as an increase in xenophobia, particularly in some political campaigns. In reply to one critical report the Federal Council noted that \"racism unfortunately is present in Switzerland\", but stated that the high proportion of foreign citizens in the country, as well as the generally unproblematic integration of foreign</s>',\n",
       "  'doc': 2,\n",
       "  'ec_query_ids': tensor([[    0,   125,  1157,   485,    19,     3,     7, 15686,    15,  7721,\n",
       "               1,     0,     0,     0,     0,     0,     0],\n",
       "          [    0,  2015, 16096,    12,     3,     7, 15686,    15,  7721,     1,\n",
       "               0,     0,     0,     0,     0,     0,     0],\n",
       "          [    0,   125,  1093,    13,     3,     7, 15686,    15,  7721,    31,\n",
       "               7,  5169,    33,  2959,  2170,    58,     1]]),\n",
       "  'ec_query_txt': ['what nationality is switzerland',\n",
       "   'largest immigrants to switzerland',\n",
       "   \"what percent of switzerland's citizens are foreign born?\"]},\n",
       " {'text': 'in some political campaigns. In reply to one critical report the Federal Council noted that \"racism unfortunately is present in Switzerland\", but stated that the high proportion of foreign citizens in the country, as well as the generally unproblematic integration of foreigners\", underlined Switzerland\\'s openness.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
       "  'doc': 2,\n",
       "  'ec_query_ids': tensor([[    0,   125,    19,     8,  1750,   344,     3,     7, 15686,    15,\n",
       "            7721,    11, 19343,     1,     0,     0,     0],\n",
       "          [    0,   125,    19,     8,  4903,    13, 21681,    16,     3,     7,\n",
       "           15686,    15,  7721,     1,     0,     0,     0],\n",
       "          [    0,   125,    19,     3,     7, 15686,    15,  7721,    31,     7,\n",
       "           10653,  1291,    58,     1,     0,     0,     0]]),\n",
       "  'ec_query_txt': ['what is the difference between switzerland and canada',\n",
       "   'what is the definition of racism in switzerland',\n",
       "   \"what is switzerland's immigration policy?\"]}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queryer._passage2chunk_map[2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embed_db",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
